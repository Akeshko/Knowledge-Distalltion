{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"X5532boXuGiL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7bc45805-674a-45ca-8372-7ff83859ad62","executionInfo":{"status":"ok","timestamp":1743636989971,"user_tz":-60,"elapsed":21257,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_vTSy-uiXWbu","outputId":"cf790d26-0165-4642-93ea-3142878cfd69","executionInfo":{"status":"ok","timestamp":1743636999610,"user_tz":-60,"elapsed":9641,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from torchvision import datasets\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","import numpy as np\n","\n","# Device configuration\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Function to calculate test accuracy\n","def evaluate_model(model, test_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = outputs.max(1)\n","            total += labels.size(0)\n","            correct += predicted.eq(labels).sum().item()\n","    accuracy = 100. * correct / total\n","    return accuracy"]},{"cell_type":"code","source":["import os\n","import time\n","import json\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Subset\n","from torchvision import datasets, transforms, models\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from copy import deepcopy\n","from tqdm import tqdm\n","\n","\n","# Create test dataset\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","test_transform = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB (3 channels)\n","    transforms.ToTensor(),  # Convert the image to tensor\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize for RGB images\n","])\n","\n","test_set = datasets.MNIST(root='./data', train=False, download=True, transform=test_transform)\n","\n","test_loader = DataLoader(\n","    test_set,\n","    batch_size=32,\n","    shuffle=False,\n","    num_workers=2\n",")\n","\n","# Example loop over the test set\n","for inputs, labels in test_loader:\n","    # Your evaluation code here\n","    print(inputs.shape, labels.shape)\n","    break"],"metadata":{"id":"Ge514Gbwx8Al","colab":{"base_uri":"https://localhost:8080/"},"outputId":"272fc1f2-80cf-48d9-e262-98ac9e8621c0","executionInfo":{"status":"ok","timestamp":1743637006187,"user_tz":-60,"elapsed":6577,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 16.2MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 482kB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 4.47MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 9.56MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 3, 28, 28]) torch.Size([32])\n"]}]},{"cell_type":"code","source":["# Teacher Model (ResNet50)\n","class TeacherModel(nn.Module):\n","    def __init__(self, num_classes=40):\n","        super().__init__()\n","        self.backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n","\n","        # Freeze early layers\n","        for param in self.backbone.parameters():\n","            param.requires_grad = False\n","        for param in self.backbone.layer3.parameters():\n","            param.requires_grad = True\n","        for param in self.backbone.layer4.parameters():\n","            param.requires_grad = True\n","\n","        # Classifier head\n","        self.backbone.fc = nn.Sequential(\n","            nn.Dropout(0.3),\n","            nn.Linear(self.backbone.fc.in_features, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(1024, num_classes))\n","\n","    def forward(self, x):\n","        return self.backbone(x)"],"metadata":{"id":"PtXgaYjy0meA","executionInfo":{"status":"ok","timestamp":1743637006201,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Student Model (ResNet18)\n","class StudentModel(nn.Module):\n","    def __init__(self, num_classes=40):\n","        super().__init__()\n","        self.backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n","        self.backbone.fc = nn.Sequential(\n","            nn.Dropout(0.2),\n","            nn.Linear(self.backbone.fc.in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes))\n","\n","    def forward(self, x):\n","        return self.backbone(x)"],"metadata":{"id":"kuxbYxWO0hFT","executionInfo":{"status":"ok","timestamp":1743637006209,"user_tz":-60,"elapsed":9,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["num_classes = 10"],"metadata":{"id":"1sjtXQshYCx5","executionInfo":{"status":"ok","timestamp":1743637006226,"user_tz":-60,"elapsed":17,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class AttentionWrapper(nn.Module):\n","    def __init__(self, base_model, num_classes, pretrained=True):\n","        super().__init__()\n","        # Use \"model\" to match checkpoint keys\n","        if base_model == 'resnet50':\n","            self.model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT if pretrained else None)\n","        else:\n","            self.model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT if pretrained else None)\n","\n","        in_features = self.model.fc.in_features\n","        self.model.fc = nn.Linear(in_features, num_classes)\n","\n","        self.attention_maps = {}\n","        self._register_hooks()\n","\n","    def _register_hooks(self):\n","        def hook_fn(name):\n","            def hook(_, __, output):\n","                self.attention_maps[name] = output.detach()\n","            return hook\n","        self.model.layer2.register_forward_hook(hook_fn('layer2'))\n","        self.model.layer4.register_forward_hook(hook_fn('layer4'))\n","\n","    def forward(self, x):\n","        self.attention_maps = {}\n","        return self.model(x)\n","\n","    def get_attention_maps(self):\n","        return [self.attention_maps.get('layer2'),\n","                self.attention_maps.get('layer4')]"],"metadata":{"id":"7LU66LALykhP","executionInfo":{"status":"ok","timestamp":1743637006229,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["teacher = AttentionWrapper('resnet50', num_classes, pretrained=False)\n","teacher.fc = nn.Linear(2048, 10)\n","teacher.load_state_dict(torch.load('/content/drive/MyDrive/KnowledgeDistillation/mnist/models/resnet50_mnist.pth', map_location=device), strict=False)\n","teacher = teacher.to(device)\n","teacher.eval()\n","\n","student_soft = AttentionWrapper('resnet18', num_classes, pretrained=False)\n","student_soft.fc = nn.Linear(512, 10)\n","student_soft.load_state_dict(torch.load('/content/drive/MyDrive/KnowledgeDistillation/mnist/models/soft_target_final.pth', map_location=device), strict=False)\n","student_soft = student_soft.to(device)\n","student_soft.eval()\n","\n","student_soft_dml = AttentionWrapper('resnet18', num_classes, pretrained=False)\n","student_soft_dml.fc = nn.Linear(512, 10)\n","student_soft_dml.load_state_dict(torch.load('/content/drive/MyDrive/KnowledgeDistillation/mnist/models/dml_resnet18_student1_final.pth', map_location=device), strict=False)\n","student_soft_dml = student_soft_dml.to(device)\n","student_soft_dml.eval()\n","\n","student_at = AttentionWrapper('resnet18', num_classes, pretrained=False)\n","student_at.fc = nn.Linear(512, 10)\n","student_at.load_state_dict(torch.load('/content/drive/MyDrive/KnowledgeDistillation/mnist/models/attention_transfer_final.pth', map_location=device), strict=False)\n","student_at = student_at.to(device)\n","student_at.eval()\n","\n","student_at_dml = AttentionWrapper('resnet18', num_classes, pretrained=False)\n","student_at_dml.fc = nn.Linear(512, 10)\n","student_at_dml.load_state_dict(torch.load('/content/drive/MyDrive/KnowledgeDistillation/mnist/models/dml_resnet18_student2_final.pth', map_location=device), strict=False)\n","student_at_dml = student_at_dml.to(device)\n","student_at_dml.eval()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":370},"collapsed":true,"id":"badflF8f8Iap","outputId":"76d9d551-2603-4ff2-b966-cb4569d39762","executionInfo":{"status":"error","timestamp":1743637007166,"user_tz":-60,"elapsed":935,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":8,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/KnowledgeDistillation/mnist/models/resnet50_mnist.pth'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-ccafce478516>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mteacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttentionWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/KnowledgeDistillation/mnist/models/resnet50_mnist.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mteacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/KnowledgeDistillation/mnist/models/resnet50_mnist.pth'"]}]},{"cell_type":"code","source":["# Knowledge Distillation (KD) Loss\n","def kl_div_loss(teacher_logits, student_logits, temperature):\n","  teacher_probs = F.softmax(teacher_logits / temperature, dim=1)\n","  student_log_probs = F.log_softmax(student_logits / temperature, dim=1)\n","  return F.kl_div(student_log_probs, teacher_probs, reduction='batchmean') * (temperature ** 2)"],"metadata":{"id":"L8mDxXcoj1gH","executionInfo":{"status":"aborted","timestamp":1743637007198,"user_tz":-60,"elapsed":0,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Binary Cross-Entropy (CE) Loss\n","def cross_entropy_loss(logits, labels):\n","  # return F.binary_cross_entropy_with_logits(logits, labels.float(), reduction='mean')\n","  # Binary Cross-Entropy Loss with logits\n","  loss_fn = nn.CrossEntropyLoss()\n","\n","  # Calculate loss\n","  loss = loss_fn(logits, labels)\n","\n","  return loss"],"metadata":{"id":"LAh81QsekIbw","executionInfo":{"status":"aborted","timestamp":1743637007200,"user_tz":-60,"elapsed":1,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kl_div_loss_soft_list = []\n","kl_div_loss_soft_dml_list = []\n","kl_div_loss_at_list = []\n","kl_div_loss_at_dml_list = []\n","\n","binary_cross_entropy_loss_teacher_list = []\n","binary_cross_entropy_loss_student_soft_list = []\n","binary_cross_entropy_loss_student_soft_dml_list = []\n","binary_cross_entropy_loss_student_at_list = []\n","binary_cross_entropy_loss_student_at_dml_list = []\n","\n","with torch.no_grad():\n","      for inputs, labels in test_loader:\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          teacher_logits = teacher(inputs)\n","          student_soft_logits = student_soft(inputs)\n","          student_at_logits = student_at(inputs)\n","          student_soft_dml_logits = student_soft_dml(inputs)\n","          student_at_dml_logits = student_at_dml(inputs)\n","\n","          print(\"Teacher Logits Shape: \", teacher_logits.shape)\n","          print(\"Student Soft Logits Shape: \", student_soft_logits.shape)\n","          print(\"Student AT Logits Shape: \", student_at_logits.shape)\n","          print(\"Student Soft DML Logits Shape: \", student_soft_dml_logits.shape)\n","          print(\"Student AT DML Logits Shape: \", student_at_dml_logits.shape)\n","          print(\"\\n\")\n","\n","          kl_div_loss_soft_list.append(kl_div_loss(teacher_logits, student_soft_logits, temperature=4.0).item())\n","          kl_div_loss_soft_dml_list.append(kl_div_loss(teacher_logits, student_soft_dml_logits, temperature=4.0).item())\n","          kl_div_loss_at_list.append(kl_div_loss(teacher_logits, student_at_logits, temperature=4.0).item())\n","          kl_div_loss_at_dml_list.append(kl_div_loss(teacher_logits, student_at_dml_logits, temperature=4.0).item())\n","\n","          binary_cross_entropy_loss_teacher_list.append(cross_entropy_loss(teacher_logits, labels).item())\n","          binary_cross_entropy_loss_student_soft_list.append(cross_entropy_loss(student_soft_logits, labels).item())\n","          binary_cross_entropy_loss_student_soft_dml_list.append(cross_entropy_loss(student_soft_dml_logits, labels).item())\n","          binary_cross_entropy_loss_student_at_list.append(cross_entropy_loss(student_at_logits, labels).item())\n","          binary_cross_entropy_loss_student_at_dml_list.append(cross_entropy_loss(student_at_dml_logits, labels).item())\n","\n","          print(\"Teacher - Student Soft KL Diversion Loss: \", kl_div_loss_soft_list[-1])\n","          print(\"Teacher - Student Soft DML KL Diversion Loss: \", kl_div_loss_soft_dml_list[-1])\n","          print(\"Teacher - Student AT KL Diversion Loss: \", kl_div_loss_at_list[-1])\n","          print(\"Teacher - Student AT DML KL Diversion Loss: \", kl_div_loss_at_dml_list[-1])\n","\n","          print(\"Teacher CE Loss: \", binary_cross_entropy_loss_teacher_list[-1])\n","          print(\"Student Soft CE Loss: \", binary_cross_entropy_loss_student_soft_list[-1])\n","          print(\"Student Soft DML CE Loss: \", binary_cross_entropy_loss_student_soft_dml_list[-1])\n","          print(\"Student AT CE Loss: \", binary_cross_entropy_loss_student_at_list[-1])\n","          print(\"Student AT DML CE Loss: \", binary_cross_entropy_loss_student_at_dml_list[-1])\n","\n","          print(\"\\n\")"],"metadata":{"id":"jR4WqceglE8p","executionInfo":{"status":"aborted","timestamp":1743637007200,"user_tz":-60,"elapsed":0,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_attention_similarity(teacher, student, loader, device, total_similarity_list, adaptation_layers=None, use_cosine=True):\n","    teacher.eval()\n","    student.eval()\n","    total_similarity = 0\n","    total_batches = 0\n","\n","    with torch.no_grad():\n","        for inputs, _ in loader:\n","            inputs = inputs.to(device)\n","\n","            # Get teacher features\n","            _ = teacher(inputs)\n","            t_atts = teacher.get_attention_maps()\n","\n","            # Get student features\n","            _ = student(inputs)\n","            s_atts = student.get_attention_maps()\n","\n","            batch_sim = 0\n","            count = 0\n","\n","            for t_att, s_att, adapt_layer in zip(t_atts, s_atts, adaptation_layers):\n","                if t_att is None or s_att is None:\n","                    continue\n","\n","                # Apply adaptation layers if provided\n","                if adapt_layer is not None:\n","                    s_att = adapt_layer(s_att)\n","\n","                # Handle spatial mismatch\n","                if t_att.shape[-2:] != s_att.shape[-2:]:\n","                    t_att = F.adaptive_avg_pool2d(t_att, s_att.shape[-2:])\n","\n","                t_flat = t_att.view(t_att.size(0), -1)\n","                s_flat = s_att.view(s_att.size(0), -1)\n","\n","                if use_cosine:\n","                    cos_sim = F.cosine_similarity(t_flat, s_flat, dim=1)\n","                    batch_sim += cos_sim.mean().item()\n","                else:\n","                    batch_sim += (torch.norm(t_flat - s_flat, p=2).item() / t_att.size(0))\n","                count += 1\n","\n","            if count > 0:\n","                total_similarity += batch_sim / count\n","                total_batches += 1\n","                print(f\"Average similarity for batch: {batch_sim / count}\")\n","                total_similarity_list.append((batch_sim / count))\n","\n","    return total_similarity / total_batches if total_batches > 0 else 0"],"metadata":{"id":"v3oPhWxYykfX","executionInfo":{"status":"aborted","timestamp":1743637007224,"user_tz":-60,"elapsed":1,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add adaptation layers for dimension matching\n","adaptation_layers = nn.ModuleList()\n","with torch.no_grad():\n","    # Get sample attention shapes\n","    dummy_input = torch.randn(2, 3, 224, 224).to(device)\n","    _ = teacher(dummy_input)\n","    teacher_atts = teacher.get_attention_maps()\n","    _ = student_at(dummy_input)\n","    student_atts = student_at.get_attention_maps()\n","\n","    for t_att, s_att in zip(teacher_atts, student_atts):\n","        if t_att is None or s_att is None:\n","            continue\n","        # Create layer to adapt student channels to teacher\n","        in_channels = s_att.shape[1]\n","        out_channels = t_att.shape[1]\n","        adaptation_layers.append(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1).to(device))"],"metadata":{"id":"bRWF6HZj-tVQ","executionInfo":{"status":"aborted","timestamp":1743637007226,"user_tz":-60,"elapsed":38664,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cosine_similarity_loss_teacher_student_at_list = []\n","calculate_attention_similarity(teacher, student_at, test_loader, device, cosine_similarity_loss_teacher_student_at_list, adaptation_layers=adaptation_layers)"],"metadata":{"id":"HioKaU7lD-31","executionInfo":{"status":"aborted","timestamp":1743637007230,"user_tz":-60,"elapsed":38667,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add adaptation layers for dimension matching\n","adaptation_layers = nn.ModuleList()\n","with torch.no_grad():\n","    # Get sample attention shapes\n","    dummy_input = torch.randn(2, 3, 224, 224).to(device)\n","    _ = teacher(dummy_input)\n","    teacher_atts = teacher.get_attention_maps()\n","    _ = student_at_dml(dummy_input)\n","    student_atts = student_at_dml.get_attention_maps()\n","\n","    for t_att, s_att in zip(teacher_atts, student_atts):\n","        if t_att is None or s_att is None:\n","            continue\n","        # Create layer to adapt student channels to teacher\n","        in_channels = s_att.shape[1]\n","        out_channels = t_att.shape[1]\n","        adaptation_layers.append(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1).to(device))"],"metadata":{"id":"UgVbevSJAQSc","executionInfo":{"status":"aborted","timestamp":1743637007232,"user_tz":-60,"elapsed":38669,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cosine_similarity_loss_teacher_student_at_dml_list = []\n","calculate_attention_similarity(teacher, student_at_dml, test_loader, device, cosine_similarity_loss_teacher_student_at_dml_list, adaptation_layers=adaptation_layers)"],"metadata":{"id":"R9m6MbX-AQPF","executionInfo":{"status":"aborted","timestamp":1743637007233,"user_tz":-60,"elapsed":38668,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add adaptation layers for dimension matching\n","adaptation_layers = nn.ModuleList()\n","with torch.no_grad():\n","    # Get sample attention shapes\n","    dummy_input = torch.randn(2, 3, 224, 224).to(device)\n","    _ = student_at(dummy_input)\n","    teacher_atts = student_at.get_attention_maps()\n","    _ = student_at_dml(dummy_input)\n","    student_atts = student_at_dml.get_attention_maps()\n","\n","    for t_att, s_att in zip(teacher_atts, student_atts):\n","        if t_att is None or s_att is None:\n","            continue\n","        # Create layer to adapt student channels to teacher\n","        in_channels = s_att.shape[1]\n","        out_channels = t_att.shape[1]\n","        adaptation_layers.append(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1).to(device))"],"metadata":{"id":"jnTCEVWiAQM_","executionInfo":{"status":"aborted","timestamp":1743637007234,"user_tz":-60,"elapsed":38669,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cosine_similarity_loss_student_at_student_at_dml_list = []\n","calculate_attention_similarity(student_at, student_at_dml, test_loader, device, cosine_similarity_loss_student_at_student_at_dml_list, adaptation_layers=adaptation_layers)"],"metadata":{"id":"ljKK4GsuAQLP","executionInfo":{"status":"aborted","timestamp":1743637007235,"user_tz":-60,"elapsed":38669,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_numbers = list(range(1, len(test_loader) + 1))"],"metadata":{"id":"YnwWpcyqAQGy","executionInfo":{"status":"aborted","timestamp":1743637007237,"user_tz":-60,"elapsed":38670,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Sample batch-wise loss data for each model and loss function\n","kl_model1 = kl_div_loss_at_list\n","bce_model1 = binary_cross_entropy_loss_student_at_list\n","cos_model1 = np.abs(cosine_similarity_loss_teacher_student_at_list)\n","\n","kl_model2 = kl_div_loss_at_dml_list\n","bce_model2 = binary_cross_entropy_loss_student_at_dml_list\n","cos_model2 = np.abs(cosine_similarity_loss_teacher_student_at_dml_list)\n","\n","# Calculate mean loss for each model and each loss function\n","mean_kl_model1 = np.mean(kl_model1)\n","mean_bce_model1 = np.mean(bce_model1)\n","mean_cos_model1 = np.mean(cos_model1)\n","\n","mean_kl_model2 = np.mean(kl_model2)\n","mean_bce_model2 = np.mean(bce_model2)\n","mean_cos_model2 = np.mean(cos_model2)\n","\n","# Create a list of means for each model and loss function\n","mean_losses_model1 = [mean_kl_model1, mean_bce_model1, mean_cos_model1]\n","mean_losses_model2 = [mean_kl_model2, mean_bce_model2, mean_cos_model2]\n","\n","# Labels for the different loss functions\n","loss_labels = ['KL Divergence', 'Binary Cross Entropy', 'Cosine Similarity']\n","\n","# Plotting the comparison using a grouped bar plot\n","width = 0.25  # Width of the bars\n","x = np.arange(len(loss_labels))  # Label positions\n","\n","fig, ax = plt.subplots()\n","\n","# Bar positions for each model\n","ax.bar(x - width, mean_losses_model1, width, label='AT', color='blue')\n","ax.bar(x, mean_losses_model2, width, label='AT + DML', color='green')\n","\n","# Add labels and title\n","ax.set_ylabel('Mean Loss')\n","ax.set_title('Comparison of Losses Across Models')\n","ax.set_xticks(x)\n","ax.set_xticklabels(loss_labels)\n","ax.legend()\n","\n","# Display the plot\n","plt.show()"],"metadata":{"id":"FORaD0mMb7vX","executionInfo":{"status":"aborted","timestamp":1743637007270,"user_tz":-60,"elapsed":38702,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Sample batch-wise loss data for each model and loss function\n","kl_model1 = kl_div_loss_at_list\n","bce_model1 = binary_cross_entropy_loss_student_at_list\n","cos_model1 = np.abs(cosine_similarity_loss_teacher_student_at_list)\n","\n","kl_model2 = kl_div_loss_at_dml_list\n","bce_model2 = binary_cross_entropy_loss_student_at_dml_list\n","cos_model2 = np.abs(cosine_similarity_loss_teacher_student_at_dml_list)\n","\n","# Calculate mean loss for each model and each loss function\n","mean_kl_model1 = np.mean(kl_model1)\n","mean_bce_model1 = np.mean(bce_model1)\n","mean_cos_model1 = np.mean(cos_model1)\n","\n","mean_kl_model2 = np.mean(kl_model2)\n","mean_bce_model2 = np.mean(bce_model2)\n","mean_cos_model2 = np.mean(cos_model2)\n","\n","# Create a list of means for each model and loss function\n","mean_losses_model1 = [0, mean_bce_model1,  0]\n","mean_losses_model2 = [0, mean_bce_model2,  0]\n","\n","# Labels for the different loss functions\n","loss_labels = ['', 'Binary Cross Entropy', '']\n","\n","# Plotting the comparison using a grouped bar plot\n","width = 0.25  # Width of the bars\n","x = np.arange(len(loss_labels))  # Label positions\n","\n","fig, ax = plt.subplots()\n","\n","# Bar positions for each model\n","ax.bar(x - width, mean_losses_model1, width, label='AT', color='blue')\n","ax.bar(x, mean_losses_model2, width, label='AT + DML', color='green')\n","\n","# Add labels and title\n","ax.set_ylabel('Mean Loss')\n","ax.set_title('Comparison of Binary Cross Entropy Loss Across Models')\n","ax.set_xticks(x)\n","ax.set_xticklabels(loss_labels)\n","ax.legend()\n","\n","# Display the plot\n","plt.show()"],"metadata":{"id":"L5cxM3wvBs-r","executionInfo":{"status":"aborted","timestamp":1743637007272,"user_tz":-60,"elapsed":38701,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Sample batch-wise loss data for each model and loss function\n","kl_model1 = kl_div_loss_at_list\n","cos_model1 = np.abs(cosine_similarity_loss_teacher_student_at_list)\n","\n","kl_model2 = kl_div_loss_at_dml_list\n","cos_model2 = np.abs(cosine_similarity_loss_teacher_student_at_dml_list)\n","\n","# Calculate mean loss for each model and each loss function\n","mean_kl_model1 = np.mean(kl_model1)\n","mean_cos_model1 = np.mean(cos_model1)\n","\n","mean_kl_model2 = np.mean(kl_model2)\n","mean_cos_model2 = np.mean(cos_model2)\n","\n","# Create a list of means for each model and loss function (only KL and Cosine)\n","mean_losses_model1 = [mean_kl_model1, mean_cos_model1]\n","mean_losses_model2 = [mean_kl_model2, mean_cos_model2]\n","\n","# Labels for the different loss functions (only KL and Cosine)\n","loss_labels = ['KL Divergence', 'Cosine Similarity']\n","\n","# Plotting the comparison using a grouped bar plot\n","width = 0.25  # Width of the bars\n","x = np.arange(len(loss_labels))  # Label positions\n","\n","fig, ax = plt.subplots()\n","\n","# Bar positions for each model\n","ax.bar(x - width, mean_losses_model1, width, label='AT', color='blue')\n","ax.bar(x, mean_losses_model2, width, label='AT + DML', color='green')\n","\n","# Add labels and title\n","ax.set_ylabel('Mean Loss')\n","ax.set_title('Comparison of KL Divergence and Cosine Similarity Losses Across Models')\n","ax.set_xticks(x)\n","ax.set_xticklabels(loss_labels)\n","ax.legend()\n","\n","# Display the plot\n","plt.show()\n"],"metadata":{"id":"PsoWn85-EY5s","executionInfo":{"status":"aborted","timestamp":1743637007282,"user_tz":-60,"elapsed":38709,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Sample batch-wise loss data for each model and loss function\n","kl_model1 = kl_div_loss_at_list\n","bce_model1 = binary_cross_entropy_loss_student_at_list\n","cos_model1 = np.abs(cosine_similarity_loss_teacher_student_at_list)\n","\n","kl_model2 = kl_div_loss_at_dml_list\n","bce_model2 = binary_cross_entropy_loss_student_at_dml_list\n","cos_model2 = np.abs(cosine_similarity_loss_teacher_student_at_dml_list)\n","\n","# Calculate mean loss for each model and each loss function\n","mean_kl_model1 = np.mean(kl_model1)\n","mean_bce_model1 = np.mean(bce_model1)\n","mean_cos_model1 = np.mean(cos_model1)\n","\n","mean_kl_model2 = np.mean(kl_model2)\n","mean_bce_model2 = np.mean(bce_model2)\n","mean_cos_model2 = np.mean(cos_model2)\n","\n","# Create a list of means for each model and loss function\n","mean_losses_model1 = [0, mean_cos_model1,  0]\n","mean_losses_model2 = [0, mean_cos_model2,  0]\n","\n","# Labels for the different loss functions\n","loss_labels = ['', 'Cosine Similarity', '']\n","\n","# Plotting the comparison using a grouped bar plot\n","width = 0.25  # Width of the bars\n","x = np.arange(len(loss_labels))  # Label positions\n","\n","fig, ax = plt.subplots()\n","\n","# Bar positions for each model\n","ax.bar(x - width, mean_losses_model1, width, label='AT', color='blue')\n","ax.bar(x, mean_losses_model2, width, label='AT + DML', color='green')\n","\n","# Add labels and title\n","ax.set_ylabel('Mean Loss')\n","ax.set_title('Comparison of Cosine Similarity Loss Across Models')\n","ax.set_xticks(x)\n","ax.set_xticklabels(loss_labels)\n","ax.legend()\n","\n","# Display the plot\n","plt.show()"],"metadata":{"id":"lYNAW5BYL3j_","executionInfo":{"status":"aborted","timestamp":1743637007283,"user_tz":-60,"elapsed":38707,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Sample batch-wise loss data for each model and loss function\n","kl_model1 = kl_div_loss_at_list\n","bce_model1 = binary_cross_entropy_loss_student_at_list\n","cos_model1 = np.abs(cosine_similarity_loss_teacher_student_at_list)\n","\n","kl_model2 = kl_div_loss_at_dml_list\n","bce_model2 = binary_cross_entropy_loss_student_at_dml_list\n","cos_model2 = np.abs(cosine_similarity_loss_teacher_student_at_dml_list)\n","\n","# Calculate mean loss for each model and each loss function\n","mean_kl_model1 = np.mean(kl_model1)\n","mean_bce_model1 = np.mean(bce_model1)\n","mean_cos_model1 = np.mean(cos_model1)\n","\n","mean_kl_model2 = np.mean(kl_model2)\n","mean_bce_model2 = np.mean(bce_model2)\n","mean_cos_model2 = np.mean(cos_model2)\n","\n","# Create a list of means for each model and loss function\n","mean_losses_model1 = [0, mean_kl_model1,  0]\n","mean_losses_model2 = [0, mean_kl_model2,  0]\n","\n","# Labels for the different loss functions\n","loss_labels = ['', 'KL Divergence', '']\n","\n","# Plotting the comparison using a grouped bar plot\n","width = 0.25  # Width of the bars\n","x = np.arange(len(loss_labels))  # Label positions\n","\n","fig, ax = plt.subplots()\n","\n","# Bar positions for each model\n","ax.bar(x - width, mean_losses_model1, width, label='AT', color='blue')\n","ax.bar(x, mean_losses_model2, width, label='AT + DML', color='green')\n","\n","# Add labels and title\n","ax.set_ylabel('Mean Loss')\n","ax.set_title('Comparison of KL Divergence Loss Across Models')\n","ax.set_xticks(x)\n","ax.set_xticklabels(loss_labels)\n","ax.legend()\n","\n","# Display the plot\n","plt.show()"],"metadata":{"id":"z2JL6nnmq-S1","executionInfo":{"status":"aborted","timestamp":1743637007284,"user_tz":-60,"elapsed":38706,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Sample batch-wise loss data for each model and loss function\n","kl_model1 = kl_div_loss_at_list\n","bce_model1 = binary_cross_entropy_loss_student_at_list\n","cos_model1 = np.abs(cosine_similarity_loss_teacher_student_at_list)\n","\n","kl_model2 = kl_div_loss_at_dml_list\n","bce_model2 = binary_cross_entropy_loss_student_at_dml_list\n","cos_model2 = np.abs(cosine_similarity_loss_teacher_student_at_dml_list)\n","\n","# Calculate mean loss for each model and each loss function\n","mean_kl_model1 = np.mean(kl_model1)\n","mean_bce_model1 = np.mean(bce_model1)\n","mean_cos_model1 = np.mean(cos_model1)\n","\n","mean_kl_model2 = np.mean(kl_model2)\n","mean_bce_model2 = np.mean(bce_model2)\n","mean_cos_model2 = np.mean(cos_model2)\n","\n","# Create a list of means for each model and loss function\n","mean_losses_model1 = [0, mean_bce_model1,  0]\n","mean_losses_model2 = [0, mean_bce_model2,  0]\n","\n","# Labels for the different loss functions\n","loss_labels = ['', 'Binary Cross Entropy', '']\n","\n","# Plotting the comparison using a grouped bar plot\n","width = 0.25  # Width of the bars\n","x = np.arange(len(loss_labels))  # Label positions\n","\n","fig, ax = plt.subplots()\n","\n","# Bar positions for each model\n","ax.bar(x - width, mean_losses_model1, width, label='AT', color='blue')\n","ax.bar(x, mean_losses_model2, width, label='AT + DML', color='green')\n","\n","# Add labels and title\n","ax.set_ylabel('Mean Loss')\n","ax.set_title('Comparison of Binary Cross Entropy Loss Across Models')\n","ax.set_xticks(x)\n","ax.set_xticklabels(loss_labels)\n","ax.legend()\n","\n","# Display the plot\n","plt.show()"],"metadata":{"id":"zkteNEX8rHvB","executionInfo":{"status":"aborted","timestamp":1743637007285,"user_tz":-60,"elapsed":38705,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Sample batch-wise loss data for each model and loss function\n","kl_model1 = kl_div_loss_soft_list\n","bce_model1 = binary_cross_entropy_loss_student_soft_list\n","cos_model1 = np.abs(cosine_similarity_loss_teacher_student_at_list)\n","\n","kl_model2 = kl_div_loss_soft_dml_list\n","bce_model2 = binary_cross_entropy_loss_student_soft_dml_list\n","cos_model2 = np.abs(cosine_similarity_loss_teacher_student_at_dml_list)\n","\n","# Calculate mean loss for each model and each loss function\n","mean_kl_model1 = np.mean(kl_model1)\n","mean_bce_model1 = np.mean(bce_model1)\n","mean_cos_model1 = np.mean(cos_model1)\n","\n","mean_kl_model2 = np.mean(kl_model2)\n","mean_bce_model2 = np.mean(bce_model2)\n","mean_cos_model2 = np.mean(cos_model2)\n","\n","# Create a list of means for each model and loss function\n","mean_losses_model1 = [0, mean_bce_model1,  0]\n","mean_losses_model2 = [0, mean_bce_model2,  0]\n","\n","# Labels for the different loss functions\n","loss_labels = ['', 'Binary Cross Entropy', '']\n","\n","# Plotting the comparison using a grouped bar plot\n","width = 0.25  # Width of the bars\n","x = np.arange(len(loss_labels))  # Label positions\n","\n","fig, ax = plt.subplots()\n","\n","# Bar positions for each model\n","ax.bar(x - width, mean_losses_model1, width, label='Soft', color='blue')\n","ax.bar(x, mean_losses_model2, width, label='Soft + DML', color='green')\n","\n","# Add labels and title\n","ax.set_ylabel('Mean Loss')\n","ax.set_title('Comparison of Binary Cross Entropy Loss Across Models')\n","ax.set_xticks(x)\n","ax.set_xticklabels(loss_labels)\n","ax.legend()\n","\n","# Display the plot\n","plt.show()"],"metadata":{"id":"r77I1y_7rTvF","executionInfo":{"status":"aborted","timestamp":1743637007286,"user_tz":-60,"elapsed":38704,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Sample batch-wise loss data for each model and loss function\n","kl_model1 = kl_div_loss_soft_list\n","bce_model1 = binary_cross_entropy_loss_student_soft_list\n","cos_model1 = np.abs(cosine_similarity_loss_teacher_student_at_list)\n","\n","kl_model2 = kl_div_loss_soft_dml_list\n","bce_model2 = binary_cross_entropy_loss_student_soft_dml_list\n","cos_model2 = np.abs(cosine_similarity_loss_teacher_student_at_dml_list)\n","\n","# Calculate mean loss for each model and each loss function\n","mean_kl_model1 = np.mean(kl_model1)\n","mean_bce_model1 = np.mean(bce_model1)\n","mean_cos_model1 = np.mean(cos_model1)\n","\n","mean_kl_model2 = np.mean(kl_model2)\n","mean_bce_model2 = np.mean(bce_model2)\n","mean_cos_model2 = np.mean(cos_model2)\n","\n","# Create a list of means for each model and loss function\n","mean_losses_model1 = [0, mean_kl_model1,  0]\n","mean_losses_model2 = [0, mean_kl_model2,  0]\n","\n","# Labels for the different loss functions\n","loss_labels = ['', 'KL Divergence', '']\n","\n","# Plotting the comparison using a grouped bar plot\n","width = 0.25  # Width of the bars\n","x = np.arange(len(loss_labels))  # Label positions\n","\n","fig, ax = plt.subplots()\n","\n","# Bar positions for each model\n","ax.bar(x - width, mean_losses_model1, width, label='Soft', color='blue')\n","ax.bar(x, mean_losses_model2, width, label='Soft + DML', color='green')\n","\n","# Add labels and title\n","ax.set_ylabel('Mean Loss')\n","ax.set_title('Comparison of KL Divergence Loss Across Models')\n","ax.set_xticks(x)\n","ax.set_xticklabels(loss_labels)\n","ax.legend()\n","\n","# Display the plot\n","plt.show()"],"metadata":{"id":"WvM_D6JfrfPN","executionInfo":{"status":"aborted","timestamp":1743637007286,"user_tz":-60,"elapsed":38702,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VWtEhL9hrkxW","executionInfo":{"status":"aborted","timestamp":1743637007298,"user_tz":-60,"elapsed":38713,"user":{"displayName":"Mamtha Mahanthesh Vathar","userId":"00892386917281795752"}}},"execution_count":null,"outputs":[]}]}